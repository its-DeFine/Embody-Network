version: '3.8'

# GPU-enabled Docker Compose for AutoGen platform with agent-net orchestrators
# Requires: NVIDIA Container Toolkit installed on host
# Usage: docker-compose -f docker-compose.yml -f docker-compose.gpu.yml up

services:
  # GPU Orchestrator from agent-net
  gpu-orchestrator:
    extends:
      file: ./orchestrator/agent-net/docker-compose.yml
      service: orchestrator
    container_name: autogen-gpu-orchestrator
    networks:
      - autogen-network
    environment:
      - ORCHESTRATOR_ID=${NODE_ID:-gpu-orch-1}
      - ORCHESTRATOR_SECRET=${ORCHESTRATOR_SECRET:-orch-secret}
    volumes:
      - orchestrator_data:/data
    labels:
      - "autogen.role=gpu-orchestrator"
      - "autogen.gpu=true"

  # Ollama LLM service with GPU
  ollama:
    extends:
      file: ./orchestrator/agent-net/docker-compose.yml
      service: ollama
    container_name: autogen-ollama
    networks:
      - autogen-network
    volumes:
      - ollama_models:/root/.ollama
    labels:
      - "autogen.role=llm-inference"
      - "autogen.gpu=true"

  # Ollama model loader
  ollama-loader:
    extends:
      file: ./orchestrator/agent-net/docker-compose.yml
      service: ollama-loader
    container_name: autogen-ollama-loader
    networks:
      - autogen-network
    depends_on:
      ollama:
        condition: service_healthy

  # Agent-net worker adapted for AutoGen
  agent-net-worker:
    extends:
      file: ./orchestrator/agent-net/docker-compose.yml
      service: worker
    container_name: autogen-agent-net-worker
    networks:
      - autogen-network
    environment:
      - ORCH_URL=http://gpu-orchestrator:9995
      - ORCH_SECRET=${ORCHESTRATOR_SECRET:-orch-secret}
      - CAPABILITY_NAME=autogen-gpu-agents
      - CAPABILITY_DESCRIPTION=AutoGen GPU agent execution with Ollama
      - RABBITMQ_URL=amqp://${RABBITMQ_USER:-admin}:${RABBITMQ_PASSWORD:-password}@rabbitmq:5672
      - REDIS_URL=redis://:${REDIS_PASSWORD:-redis-password}@redis:6379
    depends_on:
      - gpu-orchestrator
      - ollama
      - rabbitmq
      - redis

  # GPU Orchestrator Adapter - bridges agent-net with AutoGen
  orchestrator-adapter:
    build:
      context: ./orchestrator/adapter
      dockerfile: Dockerfile
    container_name: autogen-orchestrator-adapter
    ports:
      - "8002:8002"
    environment:
      - ORCHESTRATOR_ID=${NODE_ID:-gpu-orch-1}
      - NODE_HOSTNAME=${HOSTNAME:-gpu-node-1}
      - RABBITMQ_URL=amqp://${RABBITMQ_USER:-admin}:${RABBITMQ_PASSWORD:-password}@rabbitmq:5672
      - REDIS_URL=redis://:${REDIS_PASSWORD:-redis-password}@redis:6379
      - AGENT_NET_URL=http://agent-net-worker:9876
      - OLLAMA_URL=http://ollama:11434
      - ORCHESTRATOR_URL=http://gpu-orchestrator:9995
      - ORCHESTRATOR_SECRET=${ORCHESTRATOR_SECRET:-orch-secret}
      - GPU_ALLOCATION_STRATEGY=${GPU_ALLOCATION_STRATEGY:-least_loaded}
    networks:
      - autogen-network
    depends_on:
      - agent-net-worker
      - rabbitmq
      - redis
    restart: unless-stopped
    labels:
      - "autogen.role=adapter"
      - "autogen.component=gpu-bridge"

  # Update agent-manager to support GPU
  agent-manager:
    environment:
      - GPU_ADAPTER_URL=http://orchestrator-adapter:8002
      - ENABLE_GPU_DEPLOYMENT=true

  # Update API gateway to expose GPU endpoints
  api-gateway:
    environment:
      - GPU_ENDPOINTS_ENABLED=true
      - GPU_ADAPTER_URL=http://orchestrator-adapter:8002

volumes:
  ollama_models:
    driver: local
  orchestrator_data:
    driver: local

networks:
  autogen-network:
    external: true
    name: operation_autogen-network