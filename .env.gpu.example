# GPU Orchestrator Configuration
# Copy to .env.gpu and update with your values

# Node identification
NODE_ID=gpu-orch-1
HOSTNAME=gpu-node-1

# Livepeer Orchestrator
ORCHESTRATOR_SECRET=change-this-in-production
ORCHESTRATOR_ETH_ADDRESS=0x0000000000000000000000000000000000000000
ORCHESTRATOR_SERVICE_URI=https://your-orchestrator.example.com:9995

# GPU Settings
GPU_ALLOCATION_STRATEGY=least_loaded  # Options: least_loaded, round_robin, temperature
ENABLE_GPU_DEPLOYMENT=true
GPU_MEMORY_RESERVE_MB=2048  # Reserve GPU memory for system

# Ollama Models to Preload
OLLAMA_MODELS=codellama:34b-instruct-q4_k_m,llama2:13b,mistral:7b-instruct

# Payment Configuration (Livepeer)
PRICE_PER_UNIT=100000000000000  # Wei per unit
TICKET_EV=29000000000000        # Expected ticket value
MAX_FACE_VALUE=1000000000000000 # Maximum face value

# Resource Limits
MAX_AGENTS_PER_GPU=5
MAX_VRAM_UTILIZATION=90  # Percentage

# Monitoring
ENABLE_GPU_METRICS=true
GPU_METRICS_INTERVAL=30  # seconds

# Network Configuration
ORCHESTRATOR_NETWORK=arbitrum-one-mainnet
ETH_URL=https://arb1.arbitrum.io/rpc

# Agent Model Requirements (VRAM in MB)
MODEL_VRAM_CODELLAMA_34B=20000
MODEL_VRAM_CODELLAMA_13B=8000
MODEL_VRAM_CODELLAMA_7B=4000
MODEL_VRAM_LLAMA2_70B=40000
MODEL_VRAM_LLAMA2_13B=8000
MODEL_VRAM_MISTRAL_7B=4000